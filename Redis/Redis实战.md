# Redis实战

![image-20210822220931811](imgs\1.png)

![image-20210822221049877](imgs\2.png)

一个键值数据库包括了访问框架、索引模块、操作模块和存储模块四部分。

### 0、Redis的数据类型

Redis共有**字符串、列表、哈希、集合、有序集合**五种类型的对象，每种至少有两种以上的编码方式，不同编码可以在不同的使用场景上优化对象是使用效率。

Redis的对象系统带有引用计数实现的内存回收机制。

对于Redis保存的键值对来说，建总是一个字符串对象，而值则可以是只服从对象，列表对象等。

#### 0.1字符串对象

字符串对象的编码可以是raw或者embstr

如果一个字符串对象保存的是整数值，并且这个整数值可以用long类型来表示，那么字符串对象会将整数值保存成字符串。

如果只服从对象保存的是一个字符串值，并且这个字符串的**长度大于44字节就会变成简单动态字符串**否则就是SDS。

raw会用两次内存分配来构建redis，而embstr会通过调用一次内存分配来分配一块连续空间。

#### 0.2列表对象

列表对象的编码可以是在Redis3.2版本后，列表的底层统一采用quicklist实现

里面每一个结点都是ziplist

#### 0.3哈希对象

哈希对象的编码可以是ziplist或者hashtable

如果是ziplist编码会将键和值紧紧压在一起。

满足特定条件hashtable会用字典来做底层实现

1条件所有的键和值的只服从长度均小于64字节

2、键值对的数量少于512个

#### 0.5集合对象

intset或者hashtable（整数数组和哈希列表）

intset保存的都要是整数值，且不能超过512个。

#### 0.6有序集合

可以是ziplist或者skiplist

ziplist第一个结点保存member，第二个元素保存score

当有序集合对象满足以下会使用ziplist

1、有序集合保存的元素数量小于128个

2、有序集合保存的所有元素成员的长度都小于64字节

0.7Expire

`EXPIRE` 命令用于设置秒级精度的生存时间

`PEXPIRE` 命令则用于设置毫秒级精度的生存时间

`EXPIREAT` 命令接受一个键和一个秒级精度的 UNIX 时间戳为参数

`PEXPIREAT` 命令接受一个键和一个毫秒级精度的 UNIX 时间戳为参数

### 1、如何定位键值对的位置

依赖于数据库的**索引模块**。索引的作用是让**键值数据库根据key找到相应value的存储位置**，进而执行操作。

Redis采用**哈希表**为索引，RocksDB采用跳表为索引

### 2、快速Redis里的慢操作

![image-20210823164434531](imgs\3.png)

**1、哈希表**的冲突问题可能和rehash可能带来阻塞O(1)

rehash就是增加现有哈希桶数量，让逐渐多的元素尽可能的分散

具体，默认使用了两个全局哈希表。一开始，当你刚插入数据时，默认使用哈希表1，此时哈希表2并没有被分配空间。随着数据逐步增多，Redis开始执行rehash，这个过程分三步：

1、给哈希表2分配更大的空间，例如是当前哈希表1大小的两倍

2、把哈希表1的数据重新映射并拷贝到哈希表2中；

**3、释放哈希表1的空间**

原来的哈希表1留作下一次rehash扩容备用。

第二部涉及了大量的数据拷贝，会阻塞线程。

为了解决采用了**渐进式rehash**

**就是在处理一个请求时从哈希表1中的第一个索引位置，顺带着这个位置所有的entries拷贝到哈希表2中，等处理下一个请求就再拷贝一个**

**2、集合数据操作效率**

和String不同，一个集合类型的值，第一步是通过全局hash找到对应的哈希桶位置，第二步是在集合中操作。

![image-20210823171449365](\imgs\4.png)

复杂度是O(logN)

### 3、Redis单线程还很快

指的是Redis网络IO和键值对读写是由一个线程完成的，这也是Redis对外提供键值存储的主要流程。但是Redis其他的功能，比如持久化、异步删除、集群同步等，其实是由额外的线程执行的。

采用了多路复用机制

**IO模型与阻塞点**

![image-20210823214307276](\imgs\5.png)

潜在的阻塞点，accept()和recv()。

如果监听的端口没有数据就会一直阻塞

幸运的是socket支持非阻塞模式

**非阻塞模式**

主要体现在三个关键函数调用上

在socket模型中，不同操作调用后会返回不同的套接字类型。socket()方法会返回主动套接字，然后调用listen()方法，将主动套接字转化为监听套接字，此时，可以来监听客户端的请求。最后，调用accept()方法接收到达的客户端连接，并返回已连接套接字。

![image-20210823220319436](\imgs\6.png)

**基于多路复用的高性能I/O模型**

Linux中的IO多路复用是指一个线程处理多个IO流，就是我们听到的select/epoll机制。

Redis在单线程的情况下，允许内核中，同时存在多个监听套接字和已连接的套接字。一旦有请求来了，就会交给Redis线程处理，这就实现了一个Redis线程处理多个IO流。

![image-20210823223438479](\imgs\7.png)

**针对不同事件的发生，调用相应的处理函数（select/epoll）**

具体流程：一旦监听到FD上有请求到达，就会触发相应的事件。致谢事件会放到一个优先队列里，Redis单线程对事件队列不断进行处理，避免CPU资源的浪费。在对事件队列中的事件进行处理时，会调用响应的处理函数，这就是基于事件的回调。因为Redis一直在对事件队列进行处理，所以能及时响应客户端请求。

### 4、Redis缓存两大机制

数据库主要是由dict和expires两个字典构成，其中dict负责保存键值对，而expires字典则负责保存键的过期时间，数据库由字典构成，所有操作都是在字典之上的。

#### 1、AOF（写后日志）

redo log记录的时修改后的数据

AOF记录的是Rdis收到的每一条命令，以文本形式保存

![image-20210823225931316](.\imgs\8.png)

命令执行成功才会向AOF写入，而且不会阻塞当前操作。

##### 两个风险

1、如果刚执行完一个命令，还没有来得及记日志就宕机了，那么这个命令和相应的数据就有风险。

2、AOF也是主线程来做的，磁盘压力一大，就会减缓写盘速度。

**控制写回时机**

三种写回策略

1、Always，同步写回：每个写命令执行完，立马同步地将日志写回到磁盘

2、Everysec，每秒写回：每个命令执行完，只是先把日志写到AOF文件的内存缓冲区，每隔一秒把缓冲区的内容写回到磁盘

3、No，操作系统控制的写回,不确定会丢失多少

![image-20210824155000137](.\imgs\9.png)

由于AOF是以文件的形式存在内存中，当文件过大时，会产生性能问题

1、文件系统本身对文件大小有限制，无法保存过大的文件

2、继续追加命令记录，效率就会变低

3、如果发生宕机，AOF中的命令要一步一步被重新执行，严重影响正常使用。

对应手段：**AOF重写机制**

重写不会包含已经过期的键

就是在重写时，Redis根据数据库下现状创建一个新的AOF文件，

读取所有的键值对，然后对每一个键值对用一条命令记录它的写入。

能变小的原理就是多变一

就是多条命令变成了一条命令

![image-20210824161658703](imgs\10.png)

**AOF重写会阻塞吗**

和写回不同，重写过程是由后台线程**bgrewriteaof**来完成的，这是为了避免阻塞主线程，导致数据库性能下降。

重写过程总结成一个拷贝，两处日志

**一个拷贝**就是，每次重写主进程fork出后台的父进程的页表拷贝给bgrewriteaof子进程。然后子进程就可以在不影响主线程的情况下，逐一把拷贝数据写成操作，记入重写日志。

两处日志

因为主线程未阻塞，仍可以处理新来的操作。如果有写操作，**第一处日志就是AOF日志，用于宕机恢复**

第二处日志就是**AOF的重写日志**，也会重写到重写日志的缓冲区。这样重写日志也不会丢失最新的操作。

#### 2、内存快照RDB文件

RDB是**记录某一时刻的数据**，并不是操作，所以在做数据恢复时，我们可以直接把RDB读入内存，很快的完成恢复。

**给那些内存数据做快照？**

对于Redis总要问一个问题，阻塞主线程吗

Redis提供了两个命令来生成RDB文件，分别是save和**bgsave**

**1、save：在主线程**中执行，会导致阻塞

**2、bgsave创建一个子线程**，专门用于**写入RDB**文件，避免了主线程的阻塞，这也是RedisRDB文件生成的默认配置

**快照时数据能修改吗？**

bgsave的时候正常只能读不能写，这可不行

Redis会提供**Copy-On-Write**，**COW在执行快照的同时正常处理写操作**

bgsave子进程是由主线程fork生成的，可以共享主线程所有的内存数据。bgsave子进程运行后，开始读取主线程的内存，并写入RDB文件。

如果主线程在读，那么不影响，主线程在写，**就复制一份进行更改**，然后会**把这个副本写入RDB文件**。同时**也允许主线程同时对数据进行修改**。

**RDB也不能过快**

**可以设置在多少秒之内对数据库进行了多少次的修改**

如果频繁的执行快照会带来两方面的开销

一方面恶性循环

另一方面，子进程需要fork操作从主线程创建。虽然子进程在创建后不会再阻塞，但是**fork()**本身就会阻塞主线程

为解决以上，可以做**增量快照**，就是做了一次快照后，后续的快照**只对修改的数据进行快照记录**，这样就可以避免全量快照的开销。

全量快照做完后如果其他时刻需要快照，直接将被修改的数据写入快照文件就行。但是我们要记住那些文件被修改了。

如果直接进行记录开销较大。

**混合AOF日志和内存快照的方法**。

快照以一定频率执行，在两此快照之间，使用AOF日志记录这期间的所有命令操作。

快照记完后就清空AOF

### 4.5、Redis服务器是一个事件驱动程序

服务器处理的事件分为事件事件和文件事件两类

文件事件是对套接字的抽象，分为读事件和写事件

时间事件为定时事件和周期性事件，服务器会轮流处理这两个事件不存在抢占。

时间事件的实际处理时间通常会比设定的到达时间晚一些。

### 5、主从库的数据一致

Redis高可靠，一是数据尽量少丢失，二是服务尽量少中断。AOF和RDB保证了前者，对于后者采用增加副本冗余量，将一份数据保存在多个实例上。

#### 1、主从库间如何进行第一次同步

启动多个Redis实例的时候，他们相互之间就可以通过replicaof命令形成主库和从库的关系，之后按照三个阶段完成数据第一次同步

![image-20210824210157516](.\imgs\11.png)

从库请求同步，主库会把主库的ID和复制进度传给从库

第二个阶段发送RDB文件后，主库在内存中用专门的replication buffer记录RDB生成之后的所有操作。

第三个阶段主库会把第二阶段后新收到的命令，再发送给从库



**主从级联模式分担全量复制时的主库压力**

对于主库最耗时的操作创建RDB和传输RDB，占用fork和带宽

解决方法为主-从-从模式

![image-20210824211119661](.\imgs\12.png)

一旦主库完成了全量复制，他们之间就会一直维护一个网络连接，避免频繁建立连接的开销。

**但网络断连或阻塞依旧存在**

**断线后的处理**

PSYNC命令，进行部分重同步

1、主服务器、从服务器的复制偏移量。

2、主服务器的辅助积压缓冲区。

3、服务器的运行ID

**复制偏移量**

主服务器每次向从服务器传播N个字节的数据时，就将自己的偏移量+N

从服务器每次接收到传播来的N个字节的数据时，就将自己的复制偏移量的值+N

**复制积压缓冲区**

是一个环形缓冲区，默认大小为1MB。

发送命令时还会入队到复制积压缓冲区里面。

如果数据还在复制积压缓冲区里面，那么可以执行部分重同步，否则会完整重同步

**运行ID**

每个服务器都有自己的运行ID，初次复制的时候，主服务器会将自己运行ID传送给从服务器，而从服务器则会将这个运行ID保存起来。

如果断线重连后ID不一致就说明不是一个主服务器会进行全同步。

主服务器可以从连接断开后执行的写命令发送给从服务器，从服务器只要接受并执行这些写命令就可以实现更新。

命令传播阶段，从服务器默认每秒一次的频率向主服务器发送命令，会查看偏移量。

Redis2.8开始，网络断了之后，主从库会采用增量复制的方式继续同步。

当主库断连后，主库会把断连期间受到的写操作命令，写入replication buffer，同时也会把这些操作命令也写入repl_backlog_buffer这个缓冲区。

repl_backlog_buffer是一个环形缓冲区，**主库会记录自己写到的位置，从库则会记录自己已经读到的位置**

![image-20210824223409838](\imgs\13.png)

如果主库写的过快会导致repl_backlog_buffer是一个环形缓冲区，如果一直不读肯定会写满，就会数据不一致。

为了避免这一情况，可以调整repl_backlog_buffer的参数，缓冲区空间大小 = 主库写入命令速度 * 操作大小 - 主从库间网络传输命令速度*操作大小。

实际中repl_backlog_buffer = 缓存空间大小 * 2。

### 6、哨兵机制

**当一个哨兵启动时**

1、初始化服务器

2、将普通代码替换成哨兵专用代码

**命令表不一样**

3、初始化哨兵状态

4、初始化服务器列表

5、创建连向主服务器的连接

**每个哨兵会向主服务器建立两个链接**。一个是**命令链接，一个是订阅链接**

**获取主服务器的信息**

哨兵会默认每**十秒一次**的频率，通过命令链接**向主服务器发送INFO**，通过分析INFO返回的命令来获取主服务器当前信息。

**可以直接找到每个从服务器的位置**。

哨兵里的主服务器有从服务器字典，其键就是ip：port，值是对应的实例结构

也会以默认**十秒一次**的频率向从服务器发送INFO命令，并获取**从服务器的运行ID、链接状态、优先级、复制偏移量**。

会默认**两秒一次**向所有被监视的主从发送命令，其他哨兵结点会监听该频道，就会**分析出其他的哨兵**

**建立哨兵字典**

**创建向其他哨兵的链接。哨兵之间不会创建订阅链接**



就是一个运行在特殊模式下的Redis进程，主从库实例运行同时，它也在运行。

哨兵主要负责的就是三个任务：**监控、选主和通知**。

哨兵在进程运行时周期的给所有主从发送Ping命令，如果从库没有响应，就会标记为下线状态，如果主库没有在规定的时间内响应哨兵的Ping命令，哨兵就把它标为**下线状态**

如果主库没有在规定时间内响应哨兵的命令，就开始自动切换主库。

选完主库后哨兵把新主库的连接信息发给其他从库，让他们执行replicaof命令，和主库建立连接，并进行数据复制。而后哨兵会把新主库的连接信息通知给客户端，让他们把请求操作发到新主库上。

**监控过程**

主库有**主观下线**和**客观下线**

如果哨兵发现主库或从库对Ping命令的响应超时了，那么哨兵会把它标记为**主观下线。**

**哨兵集群中大多判断主库主观下线了**。才会将主库**客观下线**，开始选举流程。

每一个发现主服务器进入客观下线的哨兵都会要求其他哨兵将自己设置为局部领头哨兵。

就会发SENTIEL，如果接受到的leader_epoch参数的值和自己配置的一样，就表示自己是他的局部领头。

该过程也称为筛选和打分，简单来说，我们在多个从库中先按照**一定**的**筛选条件**，把不符合条件的从库去掉。然后，我们按照**一定**的**规则**，给剩下的从库逐个打分选举新的主库。

![image-20210825155219469](\imgs\14.png)

筛选条件

**选主时**，除了要检查从库的当前在线状态，还要**判断它之前的网络连接状态**。

在配置项down_after_milliseconds*10其中，down_after_milliseconds是我们认定的主库最大连接超时时间，在上述毫秒内没连上即为超时，如果超时了10次，就说明这个网络状态不好。

**之后是给从库打分**

分别按照**从库优先级、从库复制进度以及从库ID号**。只要在某一轮中有从库得分最高，那么他就是主库了，选主结束。

**第一轮：优先级最高的从库得分高**

可以通过slave-priority配置不同优先级。

**第二轮：和旧的主库同步程度最接近的从库得分高**

判断从库的slave_repl_offset最接近master_repl_offset，那么它的得分是最高的，可以作为新的主库。

**第三轮：就是看ID号**

### 7、哨兵挂了怎么办

**基于pub/sub机制的哨兵集群组成**

发布订阅机制

只有订阅了同一个频道的应用，才能通过发布的消息进行信息交换

主库上有一个**“__sent\_\_:hello”**的频道，不同哨兵就是通过它来相互发现，实现互相通信。

都把自己的ip和端口发布到频道上，就可以知道互相的端口号了

**哨兵如何知道从库的端口号呢**

由哨兵向主库发送INFO来完成

主库接收到就会把从库列表返回给哨兵



本质上哨兵是一个运行在特定模式下的Redis实例。所以每个哨兵也提供发布订阅机制，客户端可以从哨兵订阅消息

![image-20210825161931822](\imgs\15.png)

新问题，哨兵集群有多个实例，怎么确定用那个哨兵进行实际的主从切换呢

**用那个哨兵进行实际的主从切换**

在客观下线阶段，通过哨兵**配置文件中的quorum来设定赞成票数**，当一个哨兵获得仲裁所需的赞成票数后，就向其他哨兵发送命令，**希望自己来进行主从切换，并让所有其他哨兵进行投票。这个过程为Leader选举。**

投票过程中，任何一个想成为Leader的哨兵，要满足两个条件：**第一拿到半数以上的赞成票；第二拿到的票数同时还需要大于等于哨兵配置文件中的quorum值。**

选完执行官后由其完成选主操作，选完后会告知其他哨兵新的主库消息。

### 8、切片集群：数据增加了，是加内存还是加实例

越是加大内存，fork()进程就越会阻塞主线程，导致Redis变慢

**分片集群**

启动多个Redis实例组成一个集群，然后按照一定的规则，把收到的数据划分成多分，每份用一个实例来保存。如果把25G的数据平均分成5份，使用5个实例来保存，每个实例只需要保存5GB数据。

每个节点都会保存一份自己的clusterNode结构来保存自己的状态。

**纵向扩展：**

升级单个Redis实例的资源配置，好处是直接。

但是存在两个问题。

第一个问题当使用RDB持久化的时候，如果数量增加，fork子进程就会阻塞。

第二个问题硬件限制

**横向扩展：**

增加Redis实例的个数，面对百万千万规模的时候用这种更好。

最大的问题就是多个实例的分布式管理问题，

**数据切片后，在多个实例之间如何分布。**

**客户端怎么确定想要访问的数据在那个实例上。**

**数据切片和实例的对应分布关系**

Redis3.0之后开始，官方提供了一个名为Redis Cluster的方案，规定了具体细则。

**方案为哈希槽（Hash Slot）**

来处理数据和实例之间的映射关系。一个切片集群共有**16384**个哈希槽，每个键值都会根据它的key映射到一个哈希槽中。

如果16384中有任何一个槽没有得到处理，那么集群失败。

**根据Key，被映射到一个哈希槽中。**

具体的映射步骤

1、先获取对应的Key，按照CRC16（循环冗余检验）算法计算一个16bit的值；

2、然后用这个**16bit值对16384**取模，得到0~16383范围内的模数，代表一个哈希槽。

**哈希槽如何映射到具体的Redis实例上**

有N个实例，每个实例上就有16384/N个槽。

当然可以使用cluster meet命令手动建立各实例间的连接，形成集群，再用cluster addslots指定哈希槽的个数。

```react
redis-cli -h 172.16.19.3 -p 6379 cluster addslots 0,1
redis-cli -h 172.16.19.3 -p 6379 cluster addslots 2,3
redis-cli -h 172.16.19.3 -p 6379 cluster addslots 4
```

手动分配hash槽的时候要把16384个槽都用完

**客户端如何定位数据**

定位键值对数据时，它所处的哈希槽是可以计算的，要进一步定位到实例，需要知道哈希槽分布在哪个实例上

Redis实例会把自己的**哈希槽信息发给和它相连接的其他实例**，来完成哈希槽分配信息的扩散，客户端接收到哈希槽信息后，会把哈希槽信息缓存在本地。当客户端请求键值对时，会**先计算所对应的哈希槽**，然后就可以给相应的实例发送请求了。

在集群中，实例的新增和删除会引起哈希槽的变化

为了负载均衡，Redis需要把哈希槽在所有实例上**重新分布一遍**

**但是变化后Redis是知晓这种变化的**，但是客户端并不清楚发生了什么，就引发了重定向机制MOVED，就是客户端给一个实例发送数据读写，这个实例没有相应的数据，客户端要再给一个新实例发送操作命令。

MOVED 13320 172.16.19.5：6379

表示对应哈希槽在上述ip上，

![image-20210826160158351](\imgs\16.png)

**当数据正在迁移的时候**进行请求客户端会收到一条报错命令，

**ASK 13320 172.16.19.5:6379**表示哈希槽正在向目标ip迁移，此时客户端要先给172.16.19.5发送一个ASKING命令。这个命令的意思是允许客户端接下来发送的命令。然后再向这个实例发送一条GET命令。

**ASK不会更改客户端的缓存的哈希槽分配信息只允许给新实例发送一次请求**

### 9、String不好用了

String就像**万金油**一样

但是String并不适用与所有场合，它保存数据所消耗的内存空间比较多。

**集合**非常节约内存空间，但是集合是一个键对应一系列值，不适合直接保存单键的键值对。或是使用二级编码。

**为什么String类型内存开销大**

因为String需要额外的内存空间来记录数据的长度，空间使用等元数据**（简单动态字符串SDS）**。

![image-20210826165634988](\imgs\17.png)

buf是数据其他的都是额外开销，除了SDS还有来自于RedisObject结构体的开销。一个RedisObject包含8字节的元数据和一个8字节指针，这个指针再进一步指向具体数据类型的实际数据所在，

![image-20210826170535740](\imgs\18.png)

当保存的是字符串数据，且小于等于44字节时，RedisObject中的元数据，指针和SDS是一块连续的区域，可以避免内存碎片。这种布局也被称为embster编码方式。

当字符串大于44字节时，SDS数据量开始变多，Redis就不把SDS和RedisObject放在一起，而是给SDS独立的空间，并指向SDS结构。这种被称为raw编码

![image-20210826214506243](\imgs\19.png)

**用什么数据结构可以节省内存**

Redis有一种底层的数据结构，叫压缩列表（ziplist），表头有三个字段zlbytes、zltail和zllen，分别表示长度、列表尾的偏移量，以及列表中entry的个数。还有一个zlend表示结束。

**如何用集合类型保存单值的键值对**

在保存单值的键值对，可以采用基于Hash类型的二级编码方法。这里的二级编码，就是把一个单值拆分成两部分，前一部分作为Hash集合的key，后一部分作为value。

也会用压缩列表和哈希表来进行保存，一旦用了哈希就无法变成压缩列表了。如果用元素的后三位做key就可以保证hash集合元素个数不超过1000，同时把压缩表的上限值设为1000，就可以一直用压缩表来保存。

### 10、存1亿个key

#### 聚合统计

统计多个元素的聚合结果，包括：统计多个集合的共有元素（**交集统计**）

把两个集合相比，统计其中一个集合独有的元素（**差集统计**）

统计多个集合的所有元素（**并集统计**）

Set的差集、并集、交集计算复杂度高，会造成Redis实例阻塞，可以在主从集群中选择一个从库，让他们负责聚合计算，或者是把数据读取到客户端来完成聚合统计。

#### 排序统计

提供最新评论列表的场景为例

List 和 SortedSet是有序集合

List是按照元素进入List的顺序来进行排序，而Sort Set是按照元素的权重来排序。

Sorted Set的ZRANGEBYSCORE命令就可以按权重排序后返回元素

ZRANGEBYSCORE comments N-9 N，可以获得最新的10条评论

#### **二值状态统计**

**Bitmap**实现底层是String，其最小值为0，bitcount来统计所有1的个数。

**Bitmap**支持& ^  |等操作

#### 基数统计

**HyperLogLog**的空间大小永远都是固定的

每个loglog只需要花费**12KB**内存，就可以计算2^64个元素的基数。它是概率计算，有一定的误差率

![image-20210827161415218](imgs\20.png)

### 11、消息队列



服务器channels字典里保存了所有评到的订阅关系subscribe命令复制将客户端和被订阅的频道关联到这个字典里



三个需求

**1、消息保序**

**2、重复消息处理**

**3、消息可靠性认证**

重启后消息还在

**基于List的消息队列解决方案**

**其并不会通知消费者消费，消费者只能一直调用RPOP**

可以使用BRPOP进行阻塞式读取，客户端没有读到队列数据时，自动阻塞。

消费者程序就可以对比收到的消息ID和记录已处理过的消息ID，来判断当前收到的消息有没有经过处理。如果已经处理过就不处理了

全局唯一ID号需要生产者程序在发送消息前自行生成。生成后，我们在用LPUSH命令把消息插入List时需要包含这个全局唯一ID。

**List如何保证可靠性**

当从List中读取一条消息后，List就不会再留存这一条消息。所以，一旦宕机，就会导致消息没有处理完成，那么，消费者程序再次启动后，就不能再从List中读取消息。

为了留存小行星，List提供了**BRPOPLPUSH**命令，消费者会读取一个List中的消息，再插入另一个List中为留存。这样就可以搞备份了。

![image-20210827172337472](imgs\21.png)

**当消费者能力不足，就需要组成一个消费组**，一起分担处理List中的消息。但是List类型不支持消费组的实现**。这就需要Streams**

**Streams的消息队列解决方案**

XADD：插入消息，保证有序，可以生成全局唯一ID；

XREAD：用于读取消息，可以按ID读取数据；

XREADGROUP:按消费组形式读取消息；

XPENDING和XACK：XPENDING可以用来查询每个消费组已**读取但尚未缺认的消息**，XACK用来读取已经确认的消息。

![image-20210827193554727](\imgs\22.png)

### 12、如何避免单线程的阻塞

**客户端：**网络IO，键值对的CRUD，数据库操作

**磁盘：**生成快照RDB，记录AOF，

**主从结点：**主库生成、传输RDB文件

**切片集群实例：**向其他床上哈希槽信息，数据迁移

![image-20210827223947557](\imgs\23.png)

![image-20210828211103167](imgs\24.png)

### 13、缓冲区

在主节点间进行数据同步时，用来暂存主节点接收的写命令和数据。

**客户端输入输出缓冲区：**

未来避免请求发送和处理速度不匹配，服务器端给每个连接的客户端都设置了一个输入缓冲区和输出缓冲区，我们称之为客户端输入缓冲区和输出缓冲区

输入缓冲区会先把客户端发送过来的命令暂存起来，Redis主线程再从输入缓冲区中读取命令，进行处理。当Redis主线程处理完数据后，会把结果写入到输出缓冲区，再通过输出缓冲区返回给客户端。

**可能导致溢出的是下面两种**

1、写入了bigkey，比如一下子写入了多个百万级别的集合类型数据

2、服务端处理请求的速度过慢，Redis主线程出现了间歇性阻塞，无法及时正常的处理请求

如何处理

**使用CLIENT LIST命令**观察客户端状态，如果占用很大造成OOMRedis会关闭客户端。当多个客户端1连接占用的总量超过maxmemory配置项时（例如4GB），就会触发Redis进行数据淘汰。一旦数据被淘汰出Redis，就需要去后端读取该数据，降低了业务的访问性能。

如何解决

**1、把缓冲区调大**

Redis并没有提供参数可以让我们把客户端输入缓冲区调大

**2、从数据命令的发送和处理速度入手**

Redis为每个客户设置的输出缓冲区分为两部分：一部分是大小为16KB的固定缓冲空间，用来暂存OK响应和出错消息，另一部分是可以动态增加的缓冲空间，用来暂存大小可变的响应结果

**3、什么情况下会造成缓存溢出呢**

**bigkey**

**执行了MONITOR命令**

**缓冲区的大小设置的不合理**

MONITOR的输出结果会持续占用输出缓冲区，并越占越多，最后的结果就是发生溢出。所以不要在线上生产环境中持续使用MONITOR。当然，线上偶尔使用还是没有问题的。

客户端输出缓冲区是可以调大的

一般对订阅客户端设置缓冲区大小限制，缓冲区持续写入量限制，以及持续写入时间限制，可以在Redis配置文件中这样设置。

**主从集群缓冲区**

主从集群间的数据复制包括全量复制和增量复制两种。全量复制是同步所有数据，增量复制就是把主从库网络断掉的那一部分数据给到从库。

，当从节点使用的输出缓冲区。复制缓冲区一旦溢出，著阶段也会直接关闭从节点进行复制操作的连接，导致全量复制失败。

**复制积压缓冲区溢出问题**

主节点在把收到的写命令同步给从节点时，同时会把这些命令写入1复制积压缓冲区。一旦发生闪断，再次和主节点恢复连接后，从节点就会从复制积压缓冲区种，读取断连期间主节点接受到的命令，进而进行增量同步。

积压复制缓冲区是一个环形缓冲区，如果写满后就会覆盖旧命令，如果节点没有同步就会导致全量复制。

### 14、旁路缓存

Redis作为旁路缓存

Redis在数据库前端

**缓存命中**直接读取Redis

**缓存丢失**要把数据写到Redis

**只读缓存**

**读写缓存**

**读写缓存**，最新的数据在Redis中，为防止丢失，有**同步直写和异步直写**

**同步直写：**会降低缓存的访问性能,请求发给缓存同时，也会发给后端数据库进行管理，等到缓存和数据都写完数据，才会给客户端返回。这样，即使缓存宕机或发生故障最新数据还保存在数据库中，这就提供了数据可靠性保证。

**异步回写：**则是优先考虑了响应延迟。此时，所有写请求都在缓存中处理。等到这些**增改的数据要被从缓存中淘汰**出来时，缓存将他们写回后端数据库。这样一来，处理这些数据是在缓存中进行的，很快就能完成。只不过会发生掉电危险

![image-20210829165210055](\imgs\25)

### 15、缓存淘汰机制

![image-20210829170457296](\imgs\26)

建议把缓存设置成总数据量的15%到30%，兼顾访问性能和内存空间开销。

**一共6种缓存淘汰策略**

1、不淘汰数据的，只有noeviction这一种

2、会淘汰的有七种

​	设置了**过期时间**的，volatile-random、volatile-ttl、volatile-lru、volatile-lfu四种

​	在**所有数据范围**内进行淘汰，包括allkeys-lru、allkeys-radom、allkeys-lfu三种

![image-20210829172838115](\imgs\27)

noeviction，写满就不提供服务

过期时间的四种，如果一旦过期就淘汰掉

ttl会按照过期时间先后进行删除

由于lru有链表会造成额外开销，Redis对lru进行了简化，会默认**记录每个数据最近一次访问的时间戳，第一次淘汰时会随机选出N个把lru字段值最小的给淘汰出去**。这样Redis就不用维护大链表了，再次淘汰数据时，Redis需要挑选数据进入第一次淘汰时创建的集合，能入选的必须要是小于集合中最小的lru值。

推荐allkeys-lru。

淘汰的时候，干净数据直接删除，脏数据直接写回，判断就是有没有修改过，但是对于Redis没有这个概念，就需要我们修改时写入。

### 16、缓存和数据库不一致是如何发生的

**1、缓存中有数据**，那么，缓存的数据值需要和数据库中的值相同

**2、缓存中本身没有数据**，那么数据库中的值必须是最新值

除了这两种都是数据不一致，

更新数据库和删除缓存的过程中，无论这两个操作谁先谁后，只要有一个失败了，就会导致客户端读到旧值

**如何解决不一致问题**

**重试机制**

**延时双删**

**情况1：先删除缓存，再更新数据库**

**延迟双删**：会在第一次删除缓存后，延迟一段时间再次进行删除。

```
redis.delKey(x);
db.update(x);
Thread.sleep(N);
redis.delkey(x)
```

**情况2：先更新数据库值，再删除缓存值**

读到的就很少

![image-20210829210729375](\imgs\28)

### 17、解决缓存雪崩、击穿、穿透

#### 1、雪崩

**大量请求打到数据库**

**Redis宕机也会导致雪崩**

**1、解决，避免给大量数据设置相同的过期时间。**

**2、解决，服务降级，指的是发生缓存雪崩时，针对不同的数据采取不同的处理方式。**

1、当访问的是非核心服务时，**暂时停止从缓存中查询这些数据**，而是直接返回预定义的信息，空值或错误信息

2、当业务应用访问的是核心数据时，仍允许查询缓存，如果缓存缺失，可以继续**读取数据库**。

**当的确发生雪崩该怎么办**

**1、业务熔断机制，暂停业务应用对缓存系统的接口访问。**

**2、限流**

**3、事前预防，主从切换**

#### 2、击穿

某个热点数据，无法在缓存中处理，都到了后端数据库，经常发生在热点数据过期失效。

不设置过期时间。

#### 3、穿透

数据不存在，这样就会有很大的压力

两种情况

**1、业务层误操作：**字面意思

**2、恶意攻击：**专门访问没有的数据

**第一种预防方案**

在**Redis**中**确定一个空值或缺省值**

**第二种布隆过滤器**

### 18、缓存污染

当有些数据被访问的很少就是缓存污染

**LFU通过两维度进行优化**

**先看lru的后8bit访问次数最少的被淘汰**最大255

**再看lru的前8bit访问时间最久远的被淘汰**

这样很容易淘汰好数据

![image-20210829213835447](\imgs\29)

![image-20210829213952401](\imgs\30)

一般取10，LFU使用衰减时间来控制访问次数的衰减。LFU会计算当前和数据最近一次访问时间的差值，并换算成分钟单位再把这个差值除以lfu_decay_time的值

### 19、Pika数据库

使用固态硬盘

### 20、原子操作

redis提供了，加锁和原子操作

会导致两个问题

1、是加锁操作过多，会降低并发性能

2、Redis客户端需要加锁时，要用到分布式锁，实现复杂

所以就用到了原子操作

**并发访问中要对什么进行控制呢**

同一份数据的操作过程进行控制

客户端修改数据基本要两步，读取-修改-写回

Redis的原子操作采用两种方法

1、把多个操作在Redis中实现成一个操作，也就是单命令操作。

2、把多个操作写到一个Lua脚本中，以原子性方式执行单个Lua脚本。

**INCR/DECR增值/减值**操作具有互斥性

### 21、实现分布式锁

**两个要求**

**1、分布式锁的加锁和释放锁过程，涉及多个操作，在实现的时候要保证原子性。**

**2、共享存储系统保存了锁变量，要考虑保证共享系统的可靠性，进而保证锁的可靠性**

**多节点高可靠分布式锁**

**分布式锁算法Redlock**

就是客户端和多个独立的**Redis实例以此请求加锁，如果客户端能够和半数以上的实例成功地完成加锁操作，那么就认为客户端成功的拿到了分布式锁。**

**第一步，客户端获取当前时间**

**第二步，客户端按顺序依次向N个Redis实例执行加锁操作**

**第三步，一旦客户端完成了和所有Redis实例的加锁操作，客户端就有计算整个加锁过程的总耗时。**

**满足以下为加锁成功**

**条件一：客户端从超过半数的Redis实例上成功获得了锁**

**条件二：客户端获取锁的总耗时没有超过锁的有效时间**

![image-20210829223542143](\imgs\31)

### 22、Redis事务

第一步显示的开启事物。**Redis中的MULTI**

加入操作，不会立刻执行

通过EXEC命令执行

Watch用一个Watch字典来维护

**1、原子性**

1、如果客户端的操作命令本身就有错误，Redis会记下来，等我们提交的时候会拒绝所有操作。

2、命令操作的数据类型不匹配，但redis没有检查出错误。但是正确的命令会被执行，无法保证原子性

Redis没有回滚机制，只能来主动放弃执行，把暂存的命令队列清空

![image-20210829224616465](\imgs\32)

作者认为这些问题都是编程时会产生的所以上线后是不会有问题的

**2、一致性**

1、命令入队时报错

事务会放弃执行，保障一致性

2、命令入队时没报错，实施实例时报错

正确的会执行保证一致性

3、EXEC命令执行时实例发生故障

可以保证一致性

**事务没执行完不会写RDB**保证一致性，AOF可以剔除相对应的句子保证一致性

**3、隔离性**

分为命令入队和命令实施两个阶段

1、**并发操作在EXEC命令之前执行**，此时，**命令在队列中**隔离性的保证要使用WATCH机制来实现，否则隔离性无法保证；

2、**并发操作在EXEC命令后执行，此时隔离性可以保证**，因为单线程

watch机制是事务执行前监控键的变化，被其他线程修改了就放弃掉。

**4、持久性**

持久性无法保证，取决于AOF和RDB

可以在事务最后加上save保证事务的耐久性

